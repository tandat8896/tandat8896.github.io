---
title: "ƒê·∫°i S·ªë Tuy·∫øn T√≠nh ·ª®ng D·ª•ng Trong Machine Learning"
description: "T·ªïng quan ƒë·∫°i s·ªë tuy·∫øn t√≠nh: vector, ma tr·∫≠n, hyperplane, c√°c ph√©p to√°n c∆° b·∫£n v√† ·ª©ng d·ª•ng trong Machine Learning."
pubDatetime: 2025-07-05T01:00:00Z
tags:
  - linear-algebra
  - machine-learning
  - math
  - week2
  - module2
draft: false
---

> **C·∫≠p nh·∫≠t: 1h s√°ng ng√†y 5/7/2025**

# H√†nh Tr√¨nh ƒê·∫°i S·ªë Tuy·∫øn T√≠nh Trong Machine Learning: T·ª´ D·ªØ Li·ªáu ƒê·∫øn ·ª®ng D·ª•ng

## 1. M·ªü ƒë·∫ßu: V√¨ sao m·ªçi th·ª© ƒë·ªÅu th√†nh vector?

Khi h·ªçc machine learning, m√¨nh nh·∫≠n ra m·ªôt ƒëi·ªÅu th√∫ v·ªã: d·ªØ li·ªáu g√¨ r·ªìi c≈©ng chuy·ªÉn th√†nh vector. B·∫•t k·ªÉ l√† s·ªë li·ªáu, h√¨nh ·∫£nh, ch·ªØ vi·∫øt hay √¢m thanh ‚Äì t·∫•t c·∫£ ƒë·ªÅu ƒë∆∞·ª£c "n√©n" l·∫°i th√†nh m·ªôt d√£y s·ªë. M√¥ h√¨nh h·ªçc m√°y kh√¥ng c·∫ßn bi·∫øt b·∫°n ƒëang x·ª≠ l√Ω ·∫£nh m√®o hay gi√° nh√†, n√≥ ch·ªâ c·∫ßn vector, v√† x·ª≠ l√Ω theo thu·∫≠t to√°n.

---

## 2. T·ª´ d·ªØ li·ªáu th·ª±c t·∫ø ƒë·∫øn vector

**Vector l√† g√¨?**
N√≥ ƒë∆°n gi·∫£n l√† m·ªôt d√£y s·ªë. V√≠ d·ª•:
- M·ªôt cƒÉn nh√† c√≥ di·ªán t√≠ch 80m¬≤, 2 ph√≤ng ng·ªß ‚Üí `[80, 2]`
- M·ªôt qu·∫£ng c√°o ti√™u 150$ cho TV, 25$ cho radio ‚Üí `[150, 25]`

Ch·ªâ v·∫≠y th√¥i. M·ªçi th·ª© bi·∫øn th√†nh s·ªë, r·ªìi s·∫Øp x·∫øp l·∫°i th√†nh vector.

**√ù nghƒ©a domain knowledge:**
N·∫øu b·∫°n mu·ªën hi·ªÉu √Ω nghƒ©a th·∫≠t s·ª± c·ªßa t·ª´ng con s·ªë th√¨ c·∫ßn chuy√™n m√¥n ng√†nh ‚Äì v√≠ d·ª• b√°c sƒ©, chuy√™n gia t√†i ch√≠nh, nh√† b√°o... C√≤n model? N√≥ ch·ªâ c·∫ßn b·∫°n n√©m vector v√†o, th·∫ø l√† xong.

---

## 3. ƒê·∫°i s·ªë tuy·∫øn t√≠nh gi√∫p g√¨?

Khi ƒë√£ c√≥ vector, b·∫°n √°p d·ª•ng nh·ªØng g√¨ h·ªçc trong ƒë·∫°i s·ªë tuy·∫øn t√≠nh:
- Nh√¢n ma tr·∫≠n
- T√≠nh dot product
- T√¨m h·ªá s·ªë tuy·∫øn t√≠nh
- D·ª± ƒëo√°n $Y = f(X)$

N√≥i ng·∫Øn g·ªçn, m√¥ h√¨nh ch·ªâ c·∫ßn:
> "Input l√† vector ‚Üí X·ª≠ l√Ω ‚Üí Output l√† s·ªë ho·∫∑c vector kh√°c."

---

## 4. Hyperplane (Si√™u ph·∫≥ng): ƒê∆∞·ªùng th·∫≥ng ‚Äì M·∫∑t ph·∫≥ng ‚Äì Si√™u ph·∫≥ng

M·ªôt kh√°i ni·ªám r·∫•t hay g·∫∑p trong h·ªçc m√°y (ƒë·∫∑c bi·ªát l√† SVM ‚Äì m√°y vector h·ªó tr·ª£), ƒë√≥ l√† hyperplane ‚Äì si√™u ph·∫≥ng.
- Trong kh√¥ng gian 2D: m·ªôt ƒë∆∞·ªùng th·∫≥ng chia m·∫∑t ph·∫≥ng l√†m hai ph·∫ßn.
- Trong 3D: m·ªôt m·∫∑t ph·∫≥ng chia kh√¥ng gian l√†m hai n·ª≠a.
- Trong kh√¥ng gian nhi·ªÅu chi·ªÅu h∆°n (n chi·ªÅu): ta g·ªçi l√† si√™u ph·∫≥ng (hyperplane).

Hi·ªÉu ƒë∆°n gi·∫£n, si√™u ph·∫≥ng l√† "r√†o ch·∫Øn" ƒë·ªÉ ph√¢n lo·∫°i c√°c ƒëi·ªÉm d·ªØ li·ªáu. N·∫øu b·∫°n c√≥ d·ªØ li·ªáu 2 lo·∫°i, m√¥ h√¨nh s·∫Ω c·ªë g·∫Øng t√¨m ra si√™u ph·∫≥ng ƒë·ªÉ chia ch√∫ng ra sao cho h·ª£p l√Ω nh·∫•t.

**V√≠ d·ª•:**
B·∫°n c√≥ d·ªØ li·ªáu kh√°ch h√†ng g·ªìm `[tu·ªïi, thu nh·∫≠p, ƒëi·ªÉm t√≠n d·ª•ng]`. Model s·∫Ω t√¨m m·ªôt si√™u ph·∫≥ng trong kh√¥ng gian 3D ƒë·ªÉ ph√¢n bi·ªát ai l√† ng∆∞·ªùi "c√≥ kh·∫£ nƒÉng vay ƒë∆∞·ª£c" v√† "kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán".

---

## 5. Vector v√† Ma tr·∫≠n: ƒê·ªãnh nghƒ©a, v√≠ d·ª•, t√≠nh ch·∫•t

### 5.1. Vector l√† g√¨?
- Vector l√† m·ªôt d√£y c√°c con s·ªë s·∫Øp theo th·ª© t·ª±.
- M·ªói s·ªë trong vector thu·ªôc t·∫≠p s·ªë th·ª±c $\mathbb{R}$.
- V√≠ d·ª•: Vector 3 chi·ªÅu: $\vec{v} = [2, -1, 5] \in \mathbb{R}^3$
- Vector c√≥ kh√°i ni·ªám ƒë·ªô d√†i (norm), bi·ªÉu di·ªÖn ƒë·ªô "m·∫°nh" hay "xa" c·ªßa vector trong kh√¥ng gian.

### 5.2. Ma tr·∫≠n l√† g√¨?
- Ma tr·∫≠n l√† t·∫≠p h·ª£p c√°c s·ªë s·∫Øp x·∫øp theo h√†ng v√† c·ªôt.
- Ma tr·∫≠n k√≠ch th∆∞·ªõc $m \times n$ nghƒ©a l√† c√≥ $m$ d√≤ng, $n$ c·ªôt.
- Vector c·ªôt l√† ma tr·∫≠n $m \times 1$, vector h√†ng l√† $1 \times n$.
- Ma tr·∫≠n l√† c√°ch t·ªïng qu√°t h√≥a vector, d√πng ƒë·ªÉ bi·ªÉu di·ªÖn h·ªá ph∆∞∆°ng tr√¨nh, √°nh x·∫° tuy·∫øn t√≠nh, ho·∫∑c l∆∞u tr·ªØ d·ªØ li·ªáu nhi·ªÅu chi·ªÅu.

---

## 6. C√°c ph√©p to√°n c∆° b·∫£n v·ªõi vector v√† ma tr·∫≠n

### 6.1. C·ªông v√† tr·ª´ vector
C·ªông ho·∫∑c tr·ª´ t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng gi·ªØa 2 vector c√πng k√≠ch th∆∞·ªõc.

**V√≠ d·ª•:**
$\vec{a} = [1, 2], \vec{b} = [3, 4] \Rightarrow \vec{a} + \vec{b} = [4, 6]$

```python
import numpy as np
a = np.array([1,2])
b = np.array([3,4])
print(a + b)  # [4 6]
```

**T√≠nh ch·∫•t:**
- Giao ho√°n: $\vec{a} + \vec{b} = \vec{b} + \vec{a}$
- K·∫øt h·ª£p: $(\vec{a} + \vec{b}) + \vec{c} = \vec{a} + (\vec{b} + \vec{c})$
- Ph·∫ßn t·ª≠ trung h√≤a: $\vec{a} + \vec{0} = \vec{a}$
- Ph·∫ßn t·ª≠ ƒë·ªëi: $\vec{a} + (-\vec{a}) = \vec{0}$

### 6.2. Nh√¢n vector v·ªõi v√¥ h∆∞·ªõng (scalar)
Nh√¢n t·ª´ng ph·∫ßn t·ª≠ c·ªßa vector v·ªõi m·ªôt s·ªë th·ª±c $\lambda$.

**V√≠ d·ª•:**
$\lambda \cdot \vec{a} = \lambda \cdot [x_1, x_2] = [\lambda x_1, \lambda x_2]$

```python
import numpy as np
a = np.array([2, 3])
lambda_ = 5
print(lambda_ * a)  # [10 15]
```

**T√≠nh ch·∫•t:**
- Ph√¢n ph·ªëi: $\lambda(\vec{a} + \vec{b}) = \lambda\vec{a} + \lambda\vec{b}$
- G·ªôp h·ªá s·ªë: $(\lambda + \mu)\vec{a} = \lambda\vec{a} + \mu\vec{a}$

### 6.3. T√≠ch v√¥ h∆∞·ªõng (dot product)
Nh√¢n t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng r·ªìi c·ªông l·∫°i:
$\vec{a} \cdot \vec{b} = \sum a_i b_i = a_1b_1 + a_2b_2 + \dots + a_n b_n$

**Code:**
```python
a = np.array([1,2,3])
b = np.array([4,5,6])
print(np.dot(a, b))  # 32
```

**T√≠nh ch·∫•t:**
- D√πng ƒë·ªÉ t√≠nh g√≥c gi·ªØa hai vector: $\vec{a} \cdot \vec{b} = \|\vec{a}\| \|\vec{b}\| \cos(\theta)$
- N·∫øu t√≠ch v√¥ h∆∞·ªõng = 0 ‚Üí hai vector vu√¥ng g√≥c

**Gi·∫£i th√≠ch h√¨nh h·ªçc & ch·ª©ng minh:**
> üìê **Hi·ªÉu dot product theo h√¨nh h·ªçc: G√≥c ‚Äì Chi·∫øu ‚Äì H∆∞·ªõng**
>
> ‚ú¥Ô∏è **1. Dot product l√† g√¨?**  
> V·ªõi 2 vector $\vec{a}$, $\vec{b}$, dot product l√†:
> $$
> \vec{a} \cdot \vec{b} = \|\vec{a}\| \cdot \|\vec{b}\| \cdot \cos(\theta)
> $$
> ƒê√¢y l√† t√≠ch c·ªßa ƒë·ªô d√†i vector $a$, ƒë·ªô d√†i vector $b$, v√† cos c·ªßa g√≥c gi·ªØa ch√∫ng.
>
> üß≠ **2. Nghƒ©a h√¨nh h·ªçc c·ªßa t·ª´ng th√†nh ph·∫ßn**
> - $\|\vec{a}\| \cos(\theta)$: l√† ƒë·ªô d√†i h√¨nh chi·∫øu c·ªßa $\vec{a}$ l√™n h∆∞·ªõng c·ªßa $\vec{b}$
> - $\|\vec{b}\|$: l√† ƒë·ªô d√†i c·ªßa vector $\vec{b}$
>
> => **Dot product ch√≠nh l√† ƒë·ªô d√†i h√¨nh chi·∫øu c·ªßa $a$ l√™n $b$, r·ªìi nh√¢n v·ªõi ƒë·ªô d√†i $b$**
>
> üìå **T∆∞ duy h√¨nh h·ªçc:**
> - C√πng h∆∞·ªõng ‚Üí dot > 0
> - Ng∆∞·ª£c h∆∞·ªõng ‚Üí dot < 0
> - Vu√¥ng g√≥c ‚Üí dot = 0
>
> üîç **Chi ti·∫øt h∆°n:**
> N·∫øu b·∫°n c√≥ $\vec{a} = a_1 \vec{v}$, $\vec{b} = b_1 \vec{v}$ c√πng n·∫±m tr√™n h∆∞·ªõng $\vec{v}$ th√¨:
> $$
> \vec{a} \cdot \vec{b} = a_1 b_1 \|\vec{v}\|^2
> $$
> C√πng h∆∞·ªõng ‚Üí ch·ªâ kh√°c ƒë·ªô d√†i ‚Üí dot l√† t√≠ch ƒë·ªô d√†i.

**Code:**
```python
a = np.array([1,2,3])
b = np.array([4,5,6])
print(np.dot(a, b))  # 32
```

**T√≠nh ch·∫•t:**
- Giao ho√°n: $\vec{a} \cdot \vec{b} = \vec{b} \cdot \vec{a}$
- Ph√¢n ph·ªëi v·ªõi ph√©p c·ªông: $\vec{a} \cdot (\vec{b} + \vec{c}) = \vec{a} \cdot \vec{b} + \vec{a} \cdot \vec{c}$
- T∆∞∆°ng th√≠ch v·ªõi nh√¢n v√¥ h∆∞·ªõng: $(\lambda \vec{a}) \cdot \vec{b} = \lambda (\vec{a} \cdot \vec{b})$
- Chu·∫©n h√≥a vector: $\vec{a} \cdot \vec{a} = \|\vec{a}\|^2$
- Dot = 0 ‚Üî 2 vector vu√¥ng g√≥c: $\vec{a} \cdot \vec{b} = 0 \Leftrightarrow \vec{a} \perp \vec{b}$

### 6.4. T√≠ch Hadamard (element-wise)
Nh√¢n t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng:
$[1, 2, 3] \circ [4, 5, 6] = [4, 10, 18]$

```python
a = np.array([1,2,3])
b = np.array([4,5,6])
print(a * b)  # [ 4 10 18]
```

**T√≠nh ch·∫•t:**
- Kh√¥ng ph·∫£i l√† dot product!
- Ph·∫£i c√πng k√≠ch th∆∞·ªõc
- D√πng nhi·ªÅu trong deep learning (ReLU, attention...)

### 6.5. Nh√¢n ma tr·∫≠n ‚Äì vector
M·ªói d√≤ng c·ªßa ma tr·∫≠n dot v·ªõi vector.

**V√≠ d·ª•:**
$A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}, x = \begin{bmatrix} 5 \\ 6 \end{bmatrix} \Rightarrow Ax = \begin{bmatrix} 17 \\ 39 \end{bmatrix}$

```python
A = np.array([[1,2],[3,4]])
x = np.array([5,6])
print(A @ x)  # [17 39]
```

**T√≠nh ch·∫•t:**
- L√† m·ªôt √°nh x·∫° tuy·∫øn t√≠nh: $A: \mathbb{R}^n \rightarrow \mathbb{R}^m$
- Kh√¥ng giao ho√°n: $Ax \ne xA$

### 6.6. Nh√¢n ma tr·∫≠n ‚Äì ma tr·∫≠n
Nh√¢n h√†ng c·ªßa $A$ v·ªõi c·ªôt c·ªßa $B$:
$A_{m \times n}, B_{n \times p} \Rightarrow C_{m \times p}$

```python
A = np.array([[1,2],[3,4]])
B = np.array([[2,0],[1,2]])
print(A @ B)  # [[4 4]
              #  [10 8]]
```

**T√≠nh ch·∫•t:**
- K·∫øt h·ª£p: $A(BC) = (AB)C$
- Kh√¥ng giao ho√°n: $AB \ne BA$
- Ma tr·∫≠n ƒë∆°n v·ªã: $AI = IA = A$

### 6.7. Chuy·ªÉn v·ªã (Transpose)
Ho√°n ƒë·ªïi h√†ng ‚Üî c·ªôt:
$A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} \Rightarrow A^T = \begin{bmatrix} 1 & 3 \\ 2 & 4 \end{bmatrix}$

```python
A = np.array([[1,2],[3,4]])
print(A.T)  # [[1 3]
            #  [2 4]]
```

**T√≠nh ch·∫•t:**
- $(A^T)^T = A$
- $(AB)^T = B^T A^T$

### 6.8. ƒê·ªãnh th·ª©c (Determinant)
S·ªë ƒë·∫∑c tr∆∞ng cho ma tr·∫≠n vu√¥ng ‚Äì cho bi·∫øt ma tr·∫≠n c√≥ kh·∫£ ngh·ªãch kh√¥ng:
$\det(A) = 0 \Rightarrow A$ suy bi·∫øn (kh√¥ng kh·∫£ ngh·ªãch)

```python
A = np.array([[1,2],[3,4]])
print(np.linalg.det(A))  # -2.0
```

**T√≠nh ch·∫•t:**
- $\det(AB) = \det(A)\det(B)$
- $\det(I) = 1$
- Li√™n quan ƒë·∫øn th·ªÉ t√≠ch bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh

### 6.9. Ma tr·∫≠n ngh·ªãch ƒë·∫£o (Inverse)
Ma tr·∫≠n $A$ kh·∫£ ngh·ªãch n·∫øu t·ªìn t·∫°i $A^{-1}$ sao cho:
$AA^{-1} = A^{-1}A = I$

```python
A = np.array([[1,2],[3,4]])
A_inv = np.linalg.inv(A)
print(A_inv)
```

**T√≠nh ch·∫•t:**
- D√πng ƒë·ªÉ gi·∫£i nhanh h·ªá ph∆∞∆°ng tr√¨nh: $Ax = b \Rightarrow x = A^{-1}b$
- Kh√¥ng ph·∫£i ma tr·∫≠n n√†o c≈©ng c√≥ ngh·ªãch ƒë·∫£o

### 6.10. Hadamard Division (Chia t·ª´ng ph·∫ßn t·ª≠)
L√† ph√©p chia t·ª´ng ph·∫ßn t·ª≠ t∆∞∆°ng ·ª©ng c·ªßa hai vector (ho·∫∑c hai ma tr·∫≠n) c√πng k√≠ch th∆∞·ªõc:
$[10, 20, 30] \div [2, 4, 5] = [5, 5, 6]$

```python
a = np.array([10,20,30])
b = np.array([2,4,5])
print(a / b)  # [5. 5. 6.]
```

Trong ma tr·∫≠n:
$A = \begin{bmatrix} 8 & 9 \\ 12 & 6 \end{bmatrix}, B = \begin{bmatrix} 2 & 3 \\ 4 & 2 \end{bmatrix} \Rightarrow A \div B = \begin{bmatrix} 4 & 3 \\ 3 & 3 \end{bmatrix}$

**T√≠nh ch·∫•t:**
- Ph·∫£i c√πng k√≠ch th∆∞·ªõc
- Kh√¥ng li√™n quan ƒë·∫øn ph√©p nh√¢n ma tr·∫≠n hay ngh·ªãch ƒë·∫£o
- D√πng nhi·ªÅu trong deep learning, normalization, attention
- Kh√¥ng ƒë·ªãnh nghƒ©a ƒë∆∞·ª£c n·∫øu chia cho 0 (ph·∫£i x·ª≠ l√Ω ho·∫∑c clip)

---

## 7. Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh $Ax = b$

M·ªôt trong nh·ªØng m·ª•c ti√™u quan tr·ªçng nh·∫•t c·ªßa ƒë·∫°i s·ªë tuy·∫øn t√≠nh l√† gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh d·∫°ng $Ax = b$ m·ªôt c√°ch nhanh, g·ªçn, r√µ.
- $A$: ma tr·∫≠n h·ªá s·ªë (c√°c h·ªá s·ªë trong ph∆∞∆°ng tr√¨nh)
- $x$: vector ·∫©n s·ªë (c·∫ßn t√¨m)
- $b$: vector k·∫øt qu·∫£ (v·∫ø ph·∫£i)

### C√≥ bao nhi√™u l·ªùi gi·∫£i?
T√πy v√†o s·ªë ph∆∞∆°ng tr√¨nh (h√†ng) v√† s·ªë bi·∫øn (c·ªôt) m√† h·ªá c√≥ th·ªÉ c√≥:

| Tr∆∞·ªùng h·ª£p                  | K·∫øt qu·∫£                                                                 |
|----------------------------|------------------------------------------------------------------------|
| S·ªë ph∆∞∆°ng tr√¨nh = s·ªë bi·∫øn  | ‚úÖ Th∆∞·ªùng c√≥ 1 nghi·ªám duy nh·∫•t (n·∫øu kh√¥ng suy bi·∫øn)                    |
| S·ªë ph∆∞∆°ng tr√¨nh < s·ªë bi·∫øn  | üîÑ C√≥ v√¥ s·ªë nghi·ªám ‚Äì v√¨ thi·∫øu ƒëi·ªÅu ki·ªán r√†ng bu·ªôc                      |
| S·ªë ph∆∞∆°ng tr√¨nh > s·ªë bi·∫øn  | ‚ö† C√≥ th·ªÉ v√¥ nghi·ªám (n·∫øu m√¢u thu·∫´n), ho·∫∑c v·∫´n c√≥ nghi·ªám n·∫øu d∆∞ th·ª´a     |

**Code minh h·ªça:**
```python
import numpy as np
A = np.array([[2, 1], [1, 3]])
b = np.array([8, 13])
x = np.linalg.solve(A, b)
print(x)  # [3.  2.]
```

---

## 8. ·ª®ng d·ª•ng th·ª±c t·∫ø: X·ª≠ l√Ω ·∫£nh, t√°ch n·ªÅn, threshold, chu·∫©n h√≥a, overflow

### 8.1. Ki·ªÉu d·ªØ li·ªáu uint8 ch·ªâ l∆∞u ƒë∆∞·ª£c t·ª´ 0 ƒë·∫øn 255
N·∫øu b·∫°n c·ªông ho·∫∑c nh√¢n pixel ‚Üí gi√° tr·ªã c√≥ th·ªÉ v∆∞·ª£t 255. Khi ƒë√≥, NumPy ki·ªÉu uint8 s·∫Ω tr√†n s·ªë (overflow):
```python
a = np.array([250], dtype=np.uint8)
print(a + 10)  # üëâ ra 4 v√¨ 260 % 256 = 4
```

### 8.2. D√πng float ƒë·ªÉ t√≠nh ch√≠nh x√°c h∆°n
- Kh√¥ng tr√†n s·ªë, gi·ªØ ƒë∆∞·ª£c ph·∫ßn th·∫≠p ph√¢n
- Th√≠ch h·ª£p khi c·∫ßn chu·∫©n h√≥a ·∫£nh: chia cho 255 ƒë·ªÉ v·ªÅ [0,1]
- Ph√π h·ª£p cho c√°c ph√©p to√°n nh∆∞: l√†m m·ªù, tƒÉng s√°ng, tƒÉng t∆∞∆°ng ph·∫£n, t√≠nh trung b√¨nh, dot product, convolution v·ªõi ma tr·∫≠n l·ªçc

### 8.3. Chuy·ªÉn v·ªÅ uint8 ƒë·ªÉ hi·ªÉn th·ªã ho·∫∑c l∆∞u ·∫£nh
- OpenCV, Matplotlib, PIL‚Ä¶ y√™u c·∫ßu ·∫£nh c√≥ dtype l√† uint8
- Khi x·ª≠ l√Ω xong b·∫±ng float ‚Üí c·∫ßn clip v√† √©p ki·ªÉu l·∫°i:
```python
img = np.clip(img_float, 0, 255).astype(np.uint8)
```

### 8.4. ·∫¢nh grayscale t·ª´ ·∫£nh m√†u ‚Äì t·∫°i sao chia 3?
- ·∫¢nh m√†u RGB c√≥ shape: (height, width, 3)
- N·∫øu b·∫°n mu·ªën g·ªôp 3 k√™nh l·∫°i th√†nh 1 gi√° tr·ªã ƒë·ªô s√°ng:
```python
gray = (R + G + B) / 3
```
- Chia 3 ƒë·ªÉ gi·ªØ gi√° tr·ªã n·∫±m trong [0,255] ‚Üí tr√°nh tr√†n s·ªë.

### 8.5. Dot product v√† transpose trong ·∫£nh
- Khi th·ª±c hi·ªán dot product ƒë·ªÉ chuy·ªÉn ·∫£nh m√†u th√†nh x√°m:
```python
gray = img @ [0.2989, 0.5870, 0.1140]  # ho·∫∑c np.dot(img, weights)
```
- K·∫øt qu·∫£ shape s·∫Ω l√† (H, W) ho·∫∑c (H, W, 1) t√πy c√°ch vi·∫øt
- N·∫øu b·∫°n transpose: `img.transpose((1, 0, 2))` ‚Üí ch·ªâ ƒë·ªïi chi·ªÅu r·ªông ‚Üî chi·ªÅu cao, c√≤n channel gi·ªØ nguy√™n

### 8.6. cv2.threshold() ‚Äì T√°ch n·ªÅn ƒë∆°n gi·∫£n b·∫±ng ng∆∞·ª°ng

**C√∫ ph√°p:**
```python
_, output = cv2.threshold(input, threshold, max_value, cv2.THRESH_BINARY)
```
| Tham s·ªë      | √ù nghƒ©a                                 |
|--------------|-----------------------------------------|
| input        | ·∫¢nh ƒë·∫ßu v√†o (grayscale ho·∫∑c ma tr·∫≠n s·ªë) |
| threshold    | Ng∆∞·ª°ng c·∫Øt                              |
| max_value    | Gi√° tr·ªã g√°n n·∫øu > ng∆∞·ª°ng                |
| THRESH_BINARY| N·∫øu pixel > threshold ‚Üí g√°n max_value, ng∆∞·ª£c l·∫°i ‚Üí g√°n 0 |

**V√≠ d·ª•:**
```python
data = np.array([
    [0, 63, 174],
    [30, 205, 132],
    [52, 178, 210]
], dtype=np.uint8)

_, out = cv2.threshold(data, 100, 255, cv2.THRESH_BINARY)
```
- Ng∆∞·ª°ng 100
- Pixel n√†o > 100 ‚Üí g√°n 255, c√≤n l·∫°i g√°n 0

**L∆∞u √Ω:**
- Vi·ªác √©p ki·ªÉu v·ªÅ np.uint8 l√† b·∫Øt bu·ªôc v√¨ cv2.threshold() y√™u c·∫ßu input l√† ·∫£nh ki·ªÉu uint8 ho·∫∑c float32.
- N·∫øu kh√¥ng √©p ki·ªÉu, OpenCV s·∫Ω b√°o l·ªói: Unsupported depth of input image

---

## 9. So s√°nh c√°c ph√©p ƒëo ·∫£nh: abs diff, cosine, correlation, outer product vs dot product

### 9.1. D√πng Cosine Similarity thay v√¨ Absolute Difference

| Ph√©p ƒëo                | ƒê·∫∑c ƒëi·ªÉm                                 | Khi n√†o d√πng?                       |
|------------------------|------------------------------------------|-------------------------------------|
| abs(img1 - img2)       | Nh·∫°y c·∫£m v·ªõi ƒë·ªô l·ªách s√°ng/t∆∞∆°ng ph·∫£n     | Khi c·∫ßn ƒë·ªô ch√≠nh x√°c pixel          |
| cosine similarity      | ƒêo ƒë·ªô song song v·ªÅ h∆∞·ªõng, b·ªè qua ƒë·ªô d√†i  | Khi ·∫£nh gi·ªëng v·ªÅ h√¨nh d√°ng/chung    |
| correlation            | T·ªïng qu√°t h∆°n cosine, t√≠nh c·∫£ offset/scale| Khi c√≥ l·ªách tuy·∫øn t√≠nh nh·∫π         |

- üëâ Cosine kh√¥ng c·ªông ƒë∆∞·ª£c, ch·ªâ d√πng ƒë·ªÉ ƒëo g√≥c
- üëâ Correlation = Cosine t·ªïng qu√°t h∆°n, c√≥ th·ªÉ t√≠nh cho c·∫£ chu·∫©n h√≥a trung b√¨nh v√† ph∆∞∆°ng sai

### 9.2. V·∫•n ƒë·ªÅ v·ªÅ shape ‚Äì dot product v√† outer product

| Ma tr·∫≠n A | Ma tr·∫≠n B | A @ B  | √ù nghƒ©a                        |
|-----------|-----------|--------|-------------------------------|
| (2√ó1)     | (1√ó2)     | (2√ó2)  | Outer Product ‚Üí t·∫°o ma tr·∫≠n    |
| (1√ó2)     | (2√ó1)     | (1√ó1)  | Dot Product ‚Üí 1 s·ªë duy nh·∫•t    |

---

## 10. T·ªïng k·∫øt & tr·∫£i nghi·ªám c√° nh√¢n

H·ªçc machine learning, b·∫°n s·∫Ω th·∫•y m·ªçi th·ª© ƒë·ªÅu quy v·ªÅ vector v√† ma tr·∫≠n. ƒê·∫°i s·ªë tuy·∫øn t√≠nh l√† n·ªÅn t·∫£ng ƒë·ªÉ hi·ªÉu, x·ª≠ l√Ω v√† t·ªëi ∆∞u d·ªØ li·ªáu. C√≤n √Ω nghƒ©a th·ª±c s·ª± c·ªßa d·ªØ li·ªáu? ƒê√≥ l√† c√¢u chuy·ªán c·ªßa domain knowledge ‚Äì v√† l√† h√†nh tr√¨nh h·ªçc h·ªèi kh√¥ng ng·ª´ng!

> *B√†i vi·∫øt n√†y l√† t·ªïng h·ª£p tr·∫£i nghi·ªám h·ªçc t·∫≠p c·ªßa m√¨nh trong m·ªôt ng√†y h·ªçc ƒë·∫°i s·ªë tuy·∫øn t√≠nh ·ª©ng d·ª•ng cho ML. N·∫øu b·∫°n th·∫•y h·ªØu √≠ch, h√£y th·ª≠ √°p d·ª•ng c√°c v√≠ d·ª• code v√†o b√†i to√°n c·ªßa b·∫°n nh√©!* 